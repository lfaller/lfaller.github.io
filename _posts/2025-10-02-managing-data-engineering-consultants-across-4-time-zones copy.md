---
layout: post
author: lina
title:  "Multi-Source Data Integration"
date:   2025-10-06 8:00:00 -0500
categories: data-engineering
---

![Medallion Architecture -- from chaos to clarity.](/assets/images/posts/2025-10-06-multi-source-data-integration.png)

"Just pull the data from Benchling."

If only it were that simple.

You're also pulling from three different sequencing platforms, two legacy Excel trackers someone maintains "just in case," and a PostgreSQL database with a schema that was designed before anyone on the current team started.

Each source has different naming conventions. Different update frequencies. Different levels of trust. And somehow, you need to combine all of this into something your scientists can actually use.

This is where I've found the medallion architecture invaluable.

ğ—ªğ—µğ—®ğ˜ ğ—¶ğ˜€ ğ˜ğ—µğ—² ğ—ºğ—²ğ—±ğ—®ğ—¹ğ—¹ğ—¶ğ—¼ğ—» ğ—®ğ—¿ğ—°ğ—µğ—¶ğ˜ğ—²ğ—°ğ˜ğ˜‚ğ—¿ğ—²?

It's a systematic way to transform messy, multi-source data into something trustworthy and useful. Think of it as three progressive layers of refinement:

ğŸ¥‰ ğ—•ğ—¿ğ—¼ğ—»ğ˜‡ğ—² ğ—Ÿğ—®ğ˜†ğ—²ğ—¿: Raw data, exactly as it arrives

â†’ One table per source, no transformations â†’ Your source of truth for "what did we actually receive?" â†’ Preserves everything, even the weird edge cases

ğŸ¥ˆ ğ—¦ğ—¶ğ—¹ğ˜ƒğ—²ğ—¿ ğ—Ÿğ—®ğ˜†ğ—²ğ—¿: Cleaned and standardized data

â†’ Consistent naming conventions across all sources â†’ Data quality checks and validation rules applied â†’ Schema harmonization (finally, all your sample IDs match!) â†’ This is where you fix the "sample_id" vs "sampleID" vs "Sample_Identifier" problem

ğŸ¥‡ ğ—šğ—¼ğ—¹ğ—± ğ—Ÿğ—®ğ˜†ğ—²ğ—¿: Business-ready data

â†’ Domain-specific logic applied 

â†’ Aggregations and calculations complete 

â†’ Ready for scientists to query directly 

â†’ This is what powers your dashboards and tools

ğ—ªğ—µğ˜† ğ˜ğ—µğ—¶ğ˜€ ğ—ºğ—®ğ˜ğ˜ğ—²ğ—¿ğ˜€

When you serve data from the gold layer, your users don't need to know that their simple query is actually reconciling data from five different sources. They don't need to remember which system uses underscores and which uses camel case. They just get the answer they need.

And when something breaks upstream? You can trace it back through the layers without touching production data.

The bronze layer lets you say "here's exactly what we received" when debugging. The silver layer ensures consistency. The gold layer delivers value.

ğ—§ğ—µğ—² ğ—½ğ—¿ğ—®ğ—°ğ˜ğ—¶ğ—°ğ—®ğ—¹ ğ—¶ğ—ºğ—½ğ—®ğ—°ğ˜

This architecture transformed how we handled data integration at Korro. Instead of constantly troubleshooting why two datasets didn't align, we had clear stages where we could pinpoint exactly where problems originated.

More importantly, it meant scientists could trust the data they were seeing. When everything is standardized in gold, they can focus on the science instead of data wrangling.

For those of you managing multiple data sources: How are you handling schema mismatches and data reconciliation? Are you building transformations on the fly, or do you have a structured approach?